{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn            as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.optim.lr_scheduler import LRScheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchinfo\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.v2 as v2\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "import skimage.io as ski\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import auc, balanced_accuracy_score, confusion_matrix, precision_recall_fscore_support, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split, cross_val_score, ParameterGrid\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import torch.optim as optim\n",
    "\n",
    "# Miscellaneous\n",
    "import copy\n",
    "from enum import auto, Enum, unique\n",
    "import math\n",
    "import os\n",
    "from platform import python_version\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Typing\n",
    "from typing import Callable, Dict, Generator, List, Optional, Self, Set, Tuple, Union\n",
    "\n",
    "# Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython\n",
    "from IPython.display import HTML, Image\n",
    "from IPython.display import display\n",
    "from ipywidgets import Dropdown, FloatSlider, interact, IntSlider, Layout, SelectionSlider\n",
    "from ipywidgets import interact\n",
    "\n",
    "from os import listdir\n",
    "\n",
    "import skimage as ski\n",
    "\n",
    "\n",
    "from DLfunctions import Train_model, Train_modelPROB\n",
    "# from DeepLearningPyTorch import NNMode, TrainModel, RunEpoch, TrainModelSch, RunEpochSch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import DLfunctions  # Replace this with the name of your module\n",
    "\n",
    "importlib.reload(DLfunctions)\n",
    "\n",
    "from DLfunctions import Train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced= pd.read_csv(r'df_balanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>SeriesInstanceUID</th>\n",
       "      <th>SOPInstanceUID</th>\n",
       "      <th>pe_present_on_image</th>\n",
       "      <th>negative_exam_for_pe</th>\n",
       "      <th>qa_motion</th>\n",
       "      <th>qa_contrast</th>\n",
       "      <th>flow_artifact</th>\n",
       "      <th>rv_lv_ratio_gte_1</th>\n",
       "      <th>rv_lv_ratio_lt_1</th>\n",
       "      <th>leftsided_pe</th>\n",
       "      <th>chronic_pe</th>\n",
       "      <th>true_filling_defect_not_pe</th>\n",
       "      <th>rightsided_pe</th>\n",
       "      <th>acute_and_chronic_pe</th>\n",
       "      <th>central_pe</th>\n",
       "      <th>indeterminate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0038fd5f09f5</td>\n",
       "      <td>0f0fb8cd3ee9</td>\n",
       "      <td>0b5796d5a3ba</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0038fd5f09f5</td>\n",
       "      <td>0f0fb8cd3ee9</td>\n",
       "      <td>dba7058fdf23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0038fd5f09f5</td>\n",
       "      <td>0f0fb8cd3ee9</td>\n",
       "      <td>b52f05d70451</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0038fd5f09f5</td>\n",
       "      <td>0f0fb8cd3ee9</td>\n",
       "      <td>524ef86a0c4a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0038fd5f09f5</td>\n",
       "      <td>0f0fb8cd3ee9</td>\n",
       "      <td>656dbe20aa57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281995</th>\n",
       "      <td>fffda3f22362</td>\n",
       "      <td>39ca5eaafffe</td>\n",
       "      <td>ef8ea171d478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281996</th>\n",
       "      <td>fffda3f22362</td>\n",
       "      <td>39ca5eaafffe</td>\n",
       "      <td>e30001ca271a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281997</th>\n",
       "      <td>fffda3f22362</td>\n",
       "      <td>39ca5eaafffe</td>\n",
       "      <td>2eeac479445f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281998</th>\n",
       "      <td>fffda3f22362</td>\n",
       "      <td>39ca5eaafffe</td>\n",
       "      <td>472df1c77890</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281999</th>\n",
       "      <td>fffda3f22362</td>\n",
       "      <td>39ca5eaafffe</td>\n",
       "      <td>37a4796e7ea1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       StudyInstanceUID SeriesInstanceUID SOPInstanceUID  pe_present_on_image  \\\n",
       "0          0038fd5f09f5      0f0fb8cd3ee9   0b5796d5a3ba                    0   \n",
       "1          0038fd5f09f5      0f0fb8cd3ee9   dba7058fdf23                    0   \n",
       "2          0038fd5f09f5      0f0fb8cd3ee9   b52f05d70451                    0   \n",
       "3          0038fd5f09f5      0f0fb8cd3ee9   524ef86a0c4a                    0   \n",
       "4          0038fd5f09f5      0f0fb8cd3ee9   656dbe20aa57                    0   \n",
       "...                 ...               ...            ...                  ...   \n",
       "281995     fffda3f22362      39ca5eaafffe   ef8ea171d478                    0   \n",
       "281996     fffda3f22362      39ca5eaafffe   e30001ca271a                    0   \n",
       "281997     fffda3f22362      39ca5eaafffe   2eeac479445f                    0   \n",
       "281998     fffda3f22362      39ca5eaafffe   472df1c77890                    0   \n",
       "281999     fffda3f22362      39ca5eaafffe   37a4796e7ea1                    0   \n",
       "\n",
       "        negative_exam_for_pe  qa_motion  qa_contrast  flow_artifact  \\\n",
       "0                          0          0            0              0   \n",
       "1                          0          0            0              0   \n",
       "2                          0          0            0              0   \n",
       "3                          0          0            0              0   \n",
       "4                          0          0            0              0   \n",
       "...                      ...        ...          ...            ...   \n",
       "281995                     0          0            0              0   \n",
       "281996                     0          0            0              0   \n",
       "281997                     0          0            0              0   \n",
       "281998                     0          0            0              0   \n",
       "281999                     0          0            0              0   \n",
       "\n",
       "        rv_lv_ratio_gte_1  rv_lv_ratio_lt_1  leftsided_pe  chronic_pe  \\\n",
       "0                       0                 0             0           0   \n",
       "1                       0                 0             0           0   \n",
       "2                       0                 0             0           0   \n",
       "3                       0                 0             0           0   \n",
       "4                       0                 0             0           0   \n",
       "...                   ...               ...           ...         ...   \n",
       "281995                  0                 0             0           0   \n",
       "281996                  0                 0             0           0   \n",
       "281997                  0                 0             0           0   \n",
       "281998                  0                 0             0           0   \n",
       "281999                  0                 0             0           0   \n",
       "\n",
       "        true_filling_defect_not_pe  rightsided_pe  acute_and_chronic_pe  \\\n",
       "0                                0              0                     0   \n",
       "1                                0              0                     0   \n",
       "2                                0              0                     0   \n",
       "3                                0              0                     0   \n",
       "4                                0              0                     0   \n",
       "...                            ...            ...                   ...   \n",
       "281995                           0              0                     0   \n",
       "281996                           0              0                     0   \n",
       "281997                           0              0                     0   \n",
       "281998                           0              0                     0   \n",
       "281999                           0              0                     0   \n",
       "\n",
       "        central_pe  indeterminate  \n",
       "0                0              0  \n",
       "1                0              0  \n",
       "2                0              0  \n",
       "3                0              0  \n",
       "4                0              0  \n",
       "...            ...            ...  \n",
       "281995           0              0  \n",
       "281996           0              0  \n",
       "281997           0              0  \n",
       "281998           0              0  \n",
       "281999           0              0  \n",
       "\n",
       "[282000 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload CSV\n",
    "\n",
    "# csv_file_path = r'/media/diana/My Passport/desktop lenovo/train.csv'\n",
    "csv_file_path = r'/home/diana/train.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# path of data folder\n",
    "# data_folder_path =  r'/media/diana/My Passport/rsna_jpeg/train-jpegs'\n",
    "data_folder_path =  r'/home/diana/train-jpegs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chosen device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set the Device\n",
    "TORCH_DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #<! for first device: `cuda:0` \n",
    "print(f'The chosen device: {TORCH_DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients with 200 to 250 images: 7276\n",
      "Number of healthy patients: 4910\n",
      "Number of sick patients: 2366\n"
     ]
    }
   ],
   "source": [
    "#Filter patients with between 200 to 250 images\n",
    "image_counts = df.groupby('StudyInstanceUID')['SOPInstanceUID'].count()\n",
    "filtered_patients = image_counts[(image_counts >= 30) & (image_counts <= 1000)]\n",
    "filtered_patient_ids = filtered_patients.index\n",
    "filtered_df = df[df['StudyInstanceUID'].isin(filtered_patient_ids)]\n",
    "patient_status_counts = filtered_df.drop_duplicates(subset='StudyInstanceUID')['negative_exam_for_pe'].value_counts()\n",
    "\n",
    "print(f\"Number of patients with 200 to 250 images: {len(filtered_patient_ids)}\")\n",
    "print(f\"Number of healthy patients: {patient_status_counts.get(1, 0)}\")\n",
    "print(f\"Number of sick patients: {patient_status_counts.get(0, 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of patients without PE: 2366\n",
      "num of patients with pe: 2366\n"
     ]
    }
   ],
   "source": [
    "#Balance Data\n",
    "\n",
    "## all data - taking half of the neg and all pos (using JPGs)\n",
    "# delete duplicates - StudyInstanceUID\n",
    "unique_patients_df = filtered_df.drop_duplicates(subset='StudyInstanceUID')\n",
    "patient_counts = unique_patients_df['negative_exam_for_pe'].value_counts()\n",
    "balanced_unique = filtered_df.drop_duplicates(subset='StudyInstanceUID')\n",
    "\n",
    "#num of neg to take as num of positives\n",
    "neg_bal_patients = balanced_unique[balanced_unique['negative_exam_for_pe'] == 1].head(patient_counts[0])\n",
    "#num of pos - all pos\n",
    "pos_bal_patients = balanced_unique[balanced_unique['negative_exam_for_pe'] == 0]\n",
    "\n",
    "neg_bal_patients_ids = neg_bal_patients['StudyInstanceUID'].tolist()\n",
    "pos_bal_patients_ids = pos_bal_patients['StudyInstanceUID'].tolist()\n",
    "\n",
    "print(f\"num of patients without PE: {len(neg_bal_patients)}\")\n",
    "print(f\"num of patients with pe: {len(pos_bal_patients)}\")\n",
    "\n",
    "#df\n",
    "balanced_patients=pd.concat([neg_bal_patients, pos_bal_patients], ignore_index=True)\n",
    "#list of all IDs\n",
    "ids_balanced=neg_bal_patients_ids + pos_bal_patients_ids\n",
    "# extracting from original csv to a new working file\n",
    "\n",
    "\n",
    "# df_balanced=filtered_df[filtered_df['StudyInstanceUID'].isin(ids_balanced)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def select_10_images_per_patient(df_balanced, root_dir):\n",
    " \n",
    "#     # List to store the selected rows\n",
    "#     selected_rows = []\n",
    "\n",
    "#     # Group by StudyInstanceUID (Patient ID)\n",
    "#     grouped = df_balanced.groupby('StudyInstanceUID')\n",
    "\n",
    "#     # Loop over each patient group\n",
    "#     for patient_id, group in grouped:\n",
    "#         group_series = group['SeriesInstanceUID'].unique()[0]  # Get the unique series for the patient\n",
    "\n",
    "#         # Path to the patient's image directory\n",
    "#         path = os.path.join(root_dir, patient_id, group_series)\n",
    "\n",
    "#         # Get the image filenames from the directory\n",
    "#         slices = os.listdir(path)\n",
    "\n",
    "#         # Filter and sort the filenames by the position part (e.g., 001_SERIAL_NUMBER)\n",
    "#         valid_slices = []\n",
    "#         for s in slices:\n",
    "#             try:\n",
    "#                 # Extract the numeric part before the first underscore\n",
    "#                 position = int(s.split('_')[0])  # Extracts the \"001\" from \"001_SERIAL_NUMBER\"\n",
    "#                 valid_slices.append((position, s))\n",
    "#             except ValueError:\n",
    "#                 # Skip files that don't follow the expected pattern\n",
    "#                 continue\n",
    "\n",
    "#         # Sort the valid slices by the numeric position\n",
    "#         valid_slices.sort(key=lambda x: x[0])\n",
    "\n",
    "#         # Extract just the filenames (sorted by position)\n",
    "#         sorted_slices = [s[1] for s in valid_slices]\n",
    "\n",
    "#         # Calculate the number of images and the 55% starting index\n",
    "#         num_images = len(sorted_slices)\n",
    "#         start_idx = int(num_images * 0.50)\n",
    "\n",
    "#         # Select exactly 10 images starting from the 55% index\n",
    "#         selected_slices = sorted_slices[start_idx:start_idx + 20]\n",
    "\n",
    "#         # Print selected slices for debugging\n",
    "#         print(f\"Selected slices: {selected_slices}\")\n",
    "\n",
    "#         # Strip the serial number and .jpg extension from selected_slices to get the SOPInstanceUID\n",
    "#         db_selected_slices = [s.split('_')[1].replace('.jpg', '') for s in selected_slices]\n",
    "\n",
    "#         # Print the cleaned SOPInstanceUIDs for debugging\n",
    "#         print(f\"DB selected SOPInstanceUIDs: {db_selected_slices}\")\n",
    "\n",
    "#         # Filter the group to keep only the rows where SOPInstanceUID matches the cleaned filenames\n",
    "#         selected_group = group[group['SOPInstanceUID'].isin(db_selected_slices)]\n",
    "\n",
    "#         # Append these rows to the list\n",
    "#         selected_rows.append(selected_group)\n",
    "\n",
    "#     # Concatenate all the selected rows into a new DataFrame\n",
    "#     new_df = pd.concat(selected_rows).reset_index(drop=True)\n",
    "\n",
    "#     return new_df\n",
    "\n",
    "\n",
    "# # Create a new DataFrame with only 10 images per patient\n",
    "# df_balanced = select_10_images_per_patient(df_balanced, root_dir=data_folder_path) #(filtered_df, root_dir=data_folder_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>SeriesInstanceUID</th>\n",
       "      <th>SOPInstanceUID</th>\n",
       "      <th>pe_present_on_image</th>\n",
       "      <th>negative_exam_for_pe</th>\n",
       "      <th>qa_motion</th>\n",
       "      <th>qa_contrast</th>\n",
       "      <th>flow_artifact</th>\n",
       "      <th>rv_lv_ratio_gte_1</th>\n",
       "      <th>rv_lv_ratio_lt_1</th>\n",
       "      <th>leftsided_pe</th>\n",
       "      <th>chronic_pe</th>\n",
       "      <th>true_filling_defect_not_pe</th>\n",
       "      <th>rightsided_pe</th>\n",
       "      <th>acute_and_chronic_pe</th>\n",
       "      <th>central_pe</th>\n",
       "      <th>indeterminate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0038fd5f09f5</td>\n",
       "      <td>0f0fb8cd3ee9</td>\n",
       "      <td>0b5796d5a3ba</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0038fd5f09f5</td>\n",
       "      <td>0f0fb8cd3ee9</td>\n",
       "      <td>dba7058fdf23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0038fd5f09f5</td>\n",
       "      <td>0f0fb8cd3ee9</td>\n",
       "      <td>b52f05d70451</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0038fd5f09f5</td>\n",
       "      <td>0f0fb8cd3ee9</td>\n",
       "      <td>524ef86a0c4a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0038fd5f09f5</td>\n",
       "      <td>0f0fb8cd3ee9</td>\n",
       "      <td>656dbe20aa57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281995</th>\n",
       "      <td>fffda3f22362</td>\n",
       "      <td>39ca5eaafffe</td>\n",
       "      <td>ef8ea171d478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281996</th>\n",
       "      <td>fffda3f22362</td>\n",
       "      <td>39ca5eaafffe</td>\n",
       "      <td>e30001ca271a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281997</th>\n",
       "      <td>fffda3f22362</td>\n",
       "      <td>39ca5eaafffe</td>\n",
       "      <td>2eeac479445f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281998</th>\n",
       "      <td>fffda3f22362</td>\n",
       "      <td>39ca5eaafffe</td>\n",
       "      <td>472df1c77890</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281999</th>\n",
       "      <td>fffda3f22362</td>\n",
       "      <td>39ca5eaafffe</td>\n",
       "      <td>37a4796e7ea1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       StudyInstanceUID SeriesInstanceUID SOPInstanceUID  pe_present_on_image  \\\n",
       "0          0038fd5f09f5      0f0fb8cd3ee9   0b5796d5a3ba                    0   \n",
       "1          0038fd5f09f5      0f0fb8cd3ee9   dba7058fdf23                    0   \n",
       "2          0038fd5f09f5      0f0fb8cd3ee9   b52f05d70451                    0   \n",
       "3          0038fd5f09f5      0f0fb8cd3ee9   524ef86a0c4a                    0   \n",
       "4          0038fd5f09f5      0f0fb8cd3ee9   656dbe20aa57                    0   \n",
       "...                 ...               ...            ...                  ...   \n",
       "281995     fffda3f22362      39ca5eaafffe   ef8ea171d478                    0   \n",
       "281996     fffda3f22362      39ca5eaafffe   e30001ca271a                    0   \n",
       "281997     fffda3f22362      39ca5eaafffe   2eeac479445f                    0   \n",
       "281998     fffda3f22362      39ca5eaafffe   472df1c77890                    0   \n",
       "281999     fffda3f22362      39ca5eaafffe   37a4796e7ea1                    0   \n",
       "\n",
       "        negative_exam_for_pe  qa_motion  qa_contrast  flow_artifact  \\\n",
       "0                          0          0            0              0   \n",
       "1                          0          0            0              0   \n",
       "2                          0          0            0              0   \n",
       "3                          0          0            0              0   \n",
       "4                          0          0            0              0   \n",
       "...                      ...        ...          ...            ...   \n",
       "281995                     0          0            0              0   \n",
       "281996                     0          0            0              0   \n",
       "281997                     0          0            0              0   \n",
       "281998                     0          0            0              0   \n",
       "281999                     0          0            0              0   \n",
       "\n",
       "        rv_lv_ratio_gte_1  rv_lv_ratio_lt_1  leftsided_pe  chronic_pe  \\\n",
       "0                       0                 0             0           0   \n",
       "1                       0                 0             0           0   \n",
       "2                       0                 0             0           0   \n",
       "3                       0                 0             0           0   \n",
       "4                       0                 0             0           0   \n",
       "...                   ...               ...           ...         ...   \n",
       "281995                  0                 0             0           0   \n",
       "281996                  0                 0             0           0   \n",
       "281997                  0                 0             0           0   \n",
       "281998                  0                 0             0           0   \n",
       "281999                  0                 0             0           0   \n",
       "\n",
       "        true_filling_defect_not_pe  rightsided_pe  acute_and_chronic_pe  \\\n",
       "0                                0              0                     0   \n",
       "1                                0              0                     0   \n",
       "2                                0              0                     0   \n",
       "3                                0              0                     0   \n",
       "4                                0              0                     0   \n",
       "...                            ...            ...                   ...   \n",
       "281995                           0              0                     0   \n",
       "281996                           0              0                     0   \n",
       "281997                           0              0                     0   \n",
       "281998                           0              0                     0   \n",
       "281999                           0              0                     0   \n",
       "\n",
       "        central_pe  indeterminate  \n",
       "0                0              0  \n",
       "1                0              0  \n",
       "2                0              0  \n",
       "3                0              0  \n",
       "4                0              0  \n",
       "...            ...            ...  \n",
       "281995           0              0  \n",
       "281996           0              0  \n",
       "281997           0              0  \n",
       "281998           0              0  \n",
       "281999           0              0  \n",
       "\n",
       "[282000 rows x 17 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fixing the valuse so 1 is positive and 0 negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flipping the values in the 'negative_exam_for_pe' column\n",
    "df_balanced['negative_exam_for_pe'] = df_balanced['negative_exam_for_pe'].apply(lambda x: 1 if x == 0 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative_exam_for_pe\n",
       "1    141000\n",
       "0    141000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced['negative_exam_for_pe'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainDataset(Dataset):\n",
    "    def __init__(self, annotations, root_dir, device=TORCH_DEVICE): \n",
    "        self.annotations = annotations\n",
    "        self.root_dir = root_dir\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        \n",
    "\n",
    "        # Group by patient ID\n",
    "        self.groups = self.annotations.groupby('StudyInstanceUID')\n",
    "        self.patient_ids =list(self.groups.groups.keys())\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "         return len(self.annotations)\n",
    "\n",
    "    def load_image(self, patient_id, idx):\n",
    "        \n",
    "        #get patient data\n",
    "        group_study = self.groups.get_group(patient_id) #patient id\n",
    "        group_series = (group_study['SeriesInstanceUID'].unique())[0] #series id\n",
    "        \n",
    "        #path of patient files\n",
    "        path=os.path.join(self.root_dir, patient_id, group_series)\n",
    "        \n",
    "        #file list of patients\n",
    "        patient_files = os.listdir(path)\n",
    "        \n",
    "        patient_file_names = [f.split('_')[-1].split('.')[0].strip() for f in patient_files]\n",
    "        \n",
    "        #find the correct file in file list\n",
    "        i_idx = patient_file_names.index(self.annotations['SOPInstanceUID'].iloc[idx])\n",
    "        \n",
    "        #path of image\n",
    "        path=os.path.join(self.root_dir, patient_id, group_series, patient_files[i_idx])\n",
    "        \n",
    "        #reading image\n",
    "        image = ski.io.imread(path)\n",
    "        # image = imread(path)\n",
    "        \n",
    "        \n",
    "        # Check if the image has only one channel, convert it to 3 channels\n",
    "        if len(image.shape) == 2 or image.shape[2] == 1:\n",
    "            image = np.stack([image] * 3, axis=-1)\n",
    "\n",
    "        # Normalize    \n",
    "        imgSize = 224\n",
    "        # imgSize = 160\n",
    "        vMean = np.array([0.485, 0.456, 0.406])\n",
    "        vStd  = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "        oPreProcess = v2.Compose([\n",
    "            v2.ToImage(), \n",
    "            v2.RandomHorizontalFlip(),\n",
    "            v2.RandomVerticalFlip(),\n",
    "            v2.RandomRotation(degrees=15),\n",
    "            v2.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
    "            v2.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "            v2.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
    "            v2.Resize(imgSize),\n",
    "            v2.CenterCrop(imgSize),\n",
    "            v2.ToDtype(torch.float32, scale=True),  \n",
    "            v2.Normalize(mean=vMean, std=vStd),  \n",
    "        ])\n",
    "\n",
    "        image = oPreProcess(image)\n",
    "        image = image.to(self.device)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        idx = int(idx)\n",
    "        \n",
    "        # patient num\n",
    "        patient_id = self.annotations['StudyInstanceUID'].iloc[idx]\n",
    "        \n",
    "        # Use the load_slices method for image loading and sampling\n",
    "        image = self.load_image(patient_id, idx) \n",
    "\n",
    "        # Split into three separate 1-channel images\n",
    "        image1 = image[0:1, :, :]  # Extract the first channel\n",
    "        image2 = image[1:2, :, :]  # Extract the second channel\n",
    "        image3 = image[2:3, :, :]  # Extract the third channel        \n",
    "        \n",
    "        image1 = image1.to(self.device)\n",
    "        image2 = image2.to(self.device)\n",
    "        image3 = image3.to(self.device)           \n",
    "\n",
    "        label = self.annotations['negative_exam_for_pe'].iloc[idx]\n",
    "        label = torch.tensor(label, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        return (image1, image2, image3), label\n",
    "        # return image, label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomValDataset(Dataset):\n",
    "    def __init__(self, annotations, root_dir, device=TORCH_DEVICE): \n",
    "        self.annotations = annotations\n",
    "        self.root_dir = root_dir\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        \n",
    "\n",
    "        # Group by patient ID\n",
    "        self.groups = self.annotations.groupby('StudyInstanceUID')\n",
    "        self.patient_ids =list(self.groups.groups.keys())\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "         return len(self.annotations)\n",
    "\n",
    "    def load_image(self, patient_id, idx):\n",
    "        \n",
    "        #get patient data\n",
    "        group_study = self.groups.get_group(patient_id) #patient id\n",
    "        group_series = (group_study['SeriesInstanceUID'].unique())[0] #series id\n",
    "        \n",
    "        #path of patient files\n",
    "        path=os.path.join(self.root_dir, patient_id, group_series)\n",
    "        \n",
    "        #file list of patients\n",
    "        patient_files = os.listdir(path)\n",
    "        \n",
    "        patient_file_names = [f.split('_')[-1].split('.')[0].strip() for f in patient_files]\n",
    "        \n",
    "        #find the correct file in file list\n",
    "        i_idx = patient_file_names.index(self.annotations['SOPInstanceUID'].iloc[idx])\n",
    "        \n",
    "        #path of image\n",
    "        path=os.path.join(self.root_dir, patient_id, group_series, patient_files[i_idx])\n",
    "        \n",
    "        #reading image\n",
    "        image = ski.io.imread(path)\n",
    "        # image = imread(path)\n",
    "        \n",
    "        \n",
    "        # Check if the image has only one channel, convert it to 3 channels\n",
    "        if len(image.shape) == 2 or image.shape[2] == 1:\n",
    "            image = np.stack([image] * 3, axis=-1)\n",
    "\n",
    "        # Normalize    \n",
    "        imgSize = 224\n",
    "        # imgSize = 160\n",
    "        vMean = np.array([0.485, 0.456, 0.406])\n",
    "        vStd  = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "        oPreProcess = v2.Compose([\n",
    "            v2.ToImage(),\n",
    "            v2.ToDtype(torch.float32, scale=True),\n",
    "            v2.Normalize(mean = vMean,std=vStd),\n",
    "        ])\n",
    "\n",
    "        image = oPreProcess(image)\n",
    "        image = image.to(self.device)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        idx = int(idx)\n",
    "        \n",
    "        # patient num\n",
    "        patient_id = self.annotations['StudyInstanceUID'].iloc[idx]\n",
    "        \n",
    "        # Use the load_slices method for image loading and sampling\n",
    "        image = self.load_image(patient_id, idx)  \n",
    "\n",
    "        # Split into three separate 1-channel images\n",
    "        image1 = image[0:1, :, :]  # Extract the first channel\n",
    "        image2 = image[1:2, :, :]  # Extract the second channel\n",
    "        image3 = image[2:3, :, :]  # Extract the third channel  \n",
    "\n",
    "        image1 = image1.to(self.device)\n",
    "        image2 = image2.to(self.device)\n",
    "        image3 = image3.to(self.device)\n",
    "                     \n",
    "                \n",
    "        label = self.annotations['negative_exam_for_pe'].iloc[idx]\n",
    "        label = torch.tensor(label, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "     \n",
    "\n",
    "        return (image1, image2, image3), label\n",
    "        # return image, label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split train test \n",
    "\n",
    "# Split train test according to patient\n",
    "group_splitter = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Get the indices for train and test sets based on groups\n",
    "train_index, val_index = next(group_splitter.split(df_balanced, df_balanced['negative_exam_for_pe'], groups=df_balanced['StudyInstanceUID']))\n",
    "\n",
    "#create train and test df's based on the indices\n",
    "train_df, val_df = df_balanced.iloc[train_index,:], df_balanced.iloc[val_index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 225600\n",
      "Testing data size: 56400\n",
      "Training num of patients: 3760\n",
      "Testing num of patients: 940\n",
      "Classes in train: [1 0]\n",
      "Classes in test: [1 0]\n"
     ]
    }
   ],
   "source": [
    "print(f'Training data size: {len(train_df)}')\n",
    "print(f'Testing data size: {len(val_df)}')\n",
    "\n",
    "print(f\"Training num of patients: {len(train_df['StudyInstanceUID'].unique())}\")\n",
    "print(f\"Testing num of patients: {len(val_df['StudyInstanceUID'].unique())}\")\n",
    "\n",
    "print(f'Classes in train: {train_df[\"negative_exam_for_pe\"].unique()}')\n",
    "print(f'Classes in test: {val_df[\"negative_exam_for_pe\"].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 225600\n",
      "Testing data size: 56400\n"
     ]
    }
   ],
   "source": [
    "# Creat Datasets\n",
    "train_dataset = CustomTrainDataset(annotations=train_df, root_dir=data_folder_path)\n",
    "val_dataset = CustomValDataset(annotations=val_df, root_dir=data_folder_path)\n",
    "# Check Data\n",
    "print(f'Training data size: {len(train_dataset)}')\n",
    "print(f'Testing data size: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last= True)\n",
    "test_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of tensors in the batch: 3\n",
      "Shape of the first channel tensor: torch.Size([32, 1, 224, 224])\n",
      "Shape of the second channel tensor: torch.Size([32, 1, 224, 224])\n",
      "Shape of the third channel tensor: torch.Size([32, 1, 224, 224])\n",
      "The batch labels dimensions: torch.Size([32, 1])\n",
      "The batch labels unique values: tensor([0., 1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#1st batch of train dataset\n",
    "\n",
    "train_images, train_labels = next(iter(train_loader)) #<! PyTorch Tensors\n",
    "\n",
    "print(f'The number of tensors in the batch: {len(train_images)}')\n",
    "print(f'Shape of the first channel tensor: {train_images[0].shape}')\n",
    "print(f'Shape of the second channel tensor: {train_images[1].shape}')\n",
    "print(f'Shape of the third channel tensor: {train_images[2].shape}')\n",
    "\n",
    "# print(f'The batch features dimensions: {train_images.shape}')\n",
    "print(f'The batch labels dimensions: {train_labels.shape}')\n",
    "print(f'The batch labels unique values: {train_labels.unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of tensors in the batch: 3\n",
      "Shape of the first channel tensor: torch.Size([32, 1, 256, 256])\n",
      "Shape of the second channel tensor: torch.Size([32, 1, 256, 256])\n",
      "Shape of the third channel tensor: torch.Size([32, 1, 256, 256])\n",
      "The batch labels dimensions: torch.Size([32, 1])\n",
      "The batch labels unique values: tensor([1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#1st batch of test dataset\n",
    "\n",
    "test_images, test_labels = next(iter(test_loader)) #<! PyTorch Tensors\n",
    "\n",
    "print(f'The number of tensors in the batch: {len(train_images)}')\n",
    "print(f'Shape of the first channel tensor: {test_images[0].shape}')\n",
    "print(f'Shape of the second channel tensor: {test_images[1].shape}')\n",
    "print(f'Shape of the third channel tensor: {test_images[2].shape}')\n",
    "\n",
    "# print(f'The batch features dimensions: {test_images.shape}')\n",
    "print(f'The batch labels dimensions: {test_labels.shape}')\n",
    "print(f'The batch labels unique values: {test_labels.unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None, dropout_rate=0.5):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        \n",
    "        # Initialize downsample if needed\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)  # Adjust shortcut connection if downsampling is required\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out += identity  # Add the residual (shortcut) connection\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class CustomConvNetWithResiduals(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes=1, dropout_rate=0.5):\n",
    "        super(CustomConvNetWithResiduals, self).__init__()\n",
    "\n",
    "        # Initial convolutional layer\n",
    "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=5, stride=2, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # self.relu = nn.LeakyReLU(negative_slope=0.01, inplace=True)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Create downsample layers for residual blocks\n",
    "        self.residual_block1_downsample = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(512)\n",
    "        )\n",
    "        \n",
    "        self.residual_block2_downsample = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, kernel_size=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(1024)\n",
    "        )\n",
    "\n",
    "        # Residual blocks\n",
    "        self.residual_block1 = ResidualBlock(256, 512, stride=2, downsample=self.residual_block1_downsample, dropout_rate=dropout_rate)\n",
    "        self.residual_block2 = ResidualBlock(512, 1024, stride=2, downsample=self.residual_block2_downsample, dropout_rate=dropout_rate)\n",
    "\n",
    "        # Global average pooling and fully connected layers\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through initial convolutional layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        # Pass through the residual blocks\n",
    "        x = self.residual_block1(x)\n",
    "        x = self.residual_block2(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# def GetModel(num_classes=1, dropout_rate=0.5) -> nn.Module:\n",
    "#     return CustomConvNetWithResiduals(num_classes=num_classes, dropout_rate=dropout_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, num_classes=1, dropout_rate=0.5):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        \n",
    "        # Three identical networks for the three channels\n",
    "        self.branch1 = CustomConvNetWithResiduals(in_channels=1, num_classes=512, dropout_rate=dropout_rate)\n",
    "        self.branch2 = CustomConvNetWithResiduals(in_channels=1, num_classes=512, dropout_rate=dropout_rate)\n",
    "        self.branch3 = CustomConvNetWithResiduals(in_channels=1, num_classes=512, dropout_rate=dropout_rate)\n",
    "        \n",
    "        # Fully connected layers after concatenation\n",
    "        self.fc1 = nn.Linear(512 * 3, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def forward(self, x1, x2, x3):\n",
    "        # Split input into three separate branches\n",
    "        # x1, x2, x3 = x  # Expect x to be a tuple of (image1, image2, image3)\n",
    "        \n",
    "        # Process each branch\n",
    "        out1 = self.branch1(x1)\n",
    "        out2 = self.branch2(x2)\n",
    "        out3 = self.branch3(x3)\n",
    "        \n",
    "        # Concatenate the outputs from the three branches\n",
    "        combined = torch.cat((out1, out2, out3), dim=1)\n",
    "        \n",
    "        # Pass through the final fully connected layers\n",
    "        combined = self.fc1(combined)\n",
    "        combined = nn.ReLU()(combined)\n",
    "        combined = self.fc2(combined)\n",
    "        \n",
    "        return combined\n",
    "\n",
    "def GetModel(num_classes=1, dropout_rate=0.5) -> nn.Module:\n",
    "    return SiameseNetwork(num_classes=num_classes, dropout_rate=dropout_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "SiameseNetwork                           [32, 1]                   --\n",
       "├─CustomConvNetWithResiduals: 1-1        [32, 512]                 --\n",
       "│    └─Conv2d: 2-1                       [32, 64, 112, 112]        3,200\n",
       "│    └─BatchNorm2d: 2-2                  [32, 64, 112, 112]        128\n",
       "│    └─ReLU: 2-3                         [32, 64, 112, 112]        --\n",
       "│    └─Conv2d: 2-4                       [32, 128, 56, 56]         204,928\n",
       "│    └─BatchNorm2d: 2-5                  [32, 128, 56, 56]         256\n",
       "│    └─ReLU: 2-6                         [32, 128, 56, 56]         --\n",
       "│    └─Conv2d: 2-7                       [32, 256, 28, 28]         295,168\n",
       "│    └─BatchNorm2d: 2-8                  [32, 256, 28, 28]         512\n",
       "│    └─ReLU: 2-9                         [32, 256, 28, 28]         --\n",
       "│    └─Dropout: 2-10                     [32, 256, 28, 28]         --\n",
       "│    └─MaxPool2d: 2-11                   [32, 256, 14, 14]         --\n",
       "│    └─ResidualBlock: 2-12               [32, 512, 7, 7]           --\n",
       "│    │    └─Sequential: 3-1              [32, 512, 7, 7]           132,096\n",
       "│    │    └─Conv2d: 3-2                  [32, 512, 7, 7]           1,179,648\n",
       "│    │    └─BatchNorm2d: 3-3             [32, 512, 7, 7]           1,024\n",
       "│    │    └─ReLU: 3-4                    [32, 512, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-5                  [32, 512, 7, 7]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-6             [32, 512, 7, 7]           1,024\n",
       "│    │    └─Dropout: 3-7                 [32, 512, 7, 7]           --\n",
       "│    │    └─ReLU: 3-8                    [32, 512, 7, 7]           --\n",
       "│    └─ResidualBlock: 2-13               [32, 1024, 4, 4]          --\n",
       "│    │    └─Sequential: 3-9              [32, 1024, 4, 4]          526,336\n",
       "│    │    └─Conv2d: 3-10                 [32, 1024, 4, 4]          4,718,592\n",
       "│    │    └─BatchNorm2d: 3-11            [32, 1024, 4, 4]          2,048\n",
       "│    │    └─ReLU: 3-12                   [32, 1024, 4, 4]          --\n",
       "│    │    └─Conv2d: 3-13                 [32, 1024, 4, 4]          9,437,184\n",
       "│    │    └─BatchNorm2d: 3-14            [32, 1024, 4, 4]          2,048\n",
       "│    │    └─Dropout: 3-15                [32, 1024, 4, 4]          --\n",
       "│    │    └─ReLU: 3-16                   [32, 1024, 4, 4]          --\n",
       "│    └─AdaptiveAvgPool2d: 2-14           [32, 1024, 1, 1]          --\n",
       "│    └─Linear: 2-15                      [32, 512]                 524,800\n",
       "│    └─ReLU: 2-16                        [32, 512]                 --\n",
       "│    └─Linear: 2-17                      [32, 512]                 262,656\n",
       "├─CustomConvNetWithResiduals: 1-2        [32, 512]                 --\n",
       "│    └─Conv2d: 2-18                      [32, 64, 112, 112]        3,200\n",
       "│    └─BatchNorm2d: 2-19                 [32, 64, 112, 112]        128\n",
       "│    └─ReLU: 2-20                        [32, 64, 112, 112]        --\n",
       "│    └─Conv2d: 2-21                      [32, 128, 56, 56]         204,928\n",
       "│    └─BatchNorm2d: 2-22                 [32, 128, 56, 56]         256\n",
       "│    └─ReLU: 2-23                        [32, 128, 56, 56]         --\n",
       "│    └─Conv2d: 2-24                      [32, 256, 28, 28]         295,168\n",
       "│    └─BatchNorm2d: 2-25                 [32, 256, 28, 28]         512\n",
       "│    └─ReLU: 2-26                        [32, 256, 28, 28]         --\n",
       "│    └─Dropout: 2-27                     [32, 256, 28, 28]         --\n",
       "│    └─MaxPool2d: 2-28                   [32, 256, 14, 14]         --\n",
       "│    └─ResidualBlock: 2-29               [32, 512, 7, 7]           --\n",
       "│    │    └─Sequential: 3-17             [32, 512, 7, 7]           132,096\n",
       "│    │    └─Conv2d: 3-18                 [32, 512, 7, 7]           1,179,648\n",
       "│    │    └─BatchNorm2d: 3-19            [32, 512, 7, 7]           1,024\n",
       "│    │    └─ReLU: 3-20                   [32, 512, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-21                 [32, 512, 7, 7]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-22            [32, 512, 7, 7]           1,024\n",
       "│    │    └─Dropout: 3-23                [32, 512, 7, 7]           --\n",
       "│    │    └─ReLU: 3-24                   [32, 512, 7, 7]           --\n",
       "│    └─ResidualBlock: 2-30               [32, 1024, 4, 4]          --\n",
       "│    │    └─Sequential: 3-25             [32, 1024, 4, 4]          526,336\n",
       "│    │    └─Conv2d: 3-26                 [32, 1024, 4, 4]          4,718,592\n",
       "│    │    └─BatchNorm2d: 3-27            [32, 1024, 4, 4]          2,048\n",
       "│    │    └─ReLU: 3-28                   [32, 1024, 4, 4]          --\n",
       "│    │    └─Conv2d: 3-29                 [32, 1024, 4, 4]          9,437,184\n",
       "│    │    └─BatchNorm2d: 3-30            [32, 1024, 4, 4]          2,048\n",
       "│    │    └─Dropout: 3-31                [32, 1024, 4, 4]          --\n",
       "│    │    └─ReLU: 3-32                   [32, 1024, 4, 4]          --\n",
       "│    └─AdaptiveAvgPool2d: 2-31           [32, 1024, 1, 1]          --\n",
       "│    └─Linear: 2-32                      [32, 512]                 524,800\n",
       "│    └─ReLU: 2-33                        [32, 512]                 --\n",
       "│    └─Linear: 2-34                      [32, 512]                 262,656\n",
       "├─CustomConvNetWithResiduals: 1-3        [32, 512]                 --\n",
       "│    └─Conv2d: 2-35                      [32, 64, 112, 112]        3,200\n",
       "│    └─BatchNorm2d: 2-36                 [32, 64, 112, 112]        128\n",
       "│    └─ReLU: 2-37                        [32, 64, 112, 112]        --\n",
       "│    └─Conv2d: 2-38                      [32, 128, 56, 56]         204,928\n",
       "│    └─BatchNorm2d: 2-39                 [32, 128, 56, 56]         256\n",
       "│    └─ReLU: 2-40                        [32, 128, 56, 56]         --\n",
       "│    └─Conv2d: 2-41                      [32, 256, 28, 28]         295,168\n",
       "│    └─BatchNorm2d: 2-42                 [32, 256, 28, 28]         512\n",
       "│    └─ReLU: 2-43                        [32, 256, 28, 28]         --\n",
       "│    └─Dropout: 2-44                     [32, 256, 28, 28]         --\n",
       "│    └─MaxPool2d: 2-45                   [32, 256, 14, 14]         --\n",
       "│    └─ResidualBlock: 2-46               [32, 512, 7, 7]           --\n",
       "│    │    └─Sequential: 3-33             [32, 512, 7, 7]           132,096\n",
       "│    │    └─Conv2d: 3-34                 [32, 512, 7, 7]           1,179,648\n",
       "│    │    └─BatchNorm2d: 3-35            [32, 512, 7, 7]           1,024\n",
       "│    │    └─ReLU: 3-36                   [32, 512, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-37                 [32, 512, 7, 7]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-38            [32, 512, 7, 7]           1,024\n",
       "│    │    └─Dropout: 3-39                [32, 512, 7, 7]           --\n",
       "│    │    └─ReLU: 3-40                   [32, 512, 7, 7]           --\n",
       "│    └─ResidualBlock: 2-47               [32, 1024, 4, 4]          --\n",
       "│    │    └─Sequential: 3-41             [32, 1024, 4, 4]          526,336\n",
       "│    │    └─Conv2d: 3-42                 [32, 1024, 4, 4]          4,718,592\n",
       "│    │    └─BatchNorm2d: 3-43            [32, 1024, 4, 4]          2,048\n",
       "│    │    └─ReLU: 3-44                   [32, 1024, 4, 4]          --\n",
       "│    │    └─Conv2d: 3-45                 [32, 1024, 4, 4]          9,437,184\n",
       "│    │    └─BatchNorm2d: 3-46            [32, 1024, 4, 4]          2,048\n",
       "│    │    └─Dropout: 3-47                [32, 1024, 4, 4]          --\n",
       "│    │    └─ReLU: 3-48                   [32, 1024, 4, 4]          --\n",
       "│    └─AdaptiveAvgPool2d: 2-48           [32, 1024, 1, 1]          --\n",
       "│    └─Linear: 2-49                      [32, 512]                 524,800\n",
       "│    └─ReLU: 2-50                        [32, 512]                 --\n",
       "│    └─Linear: 2-51                      [32, 512]                 262,656\n",
       "├─Linear: 1-4                            [32, 512]                 786,944\n",
       "├─Linear: 1-5                            [32, 1]                   513\n",
       "==========================================================================================\n",
       "Total params: 59,740,289\n",
       "Trainable params: 59,740,289\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 127.68\n",
       "==========================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 2349.99\n",
       "Params size (MB): 238.96\n",
       "Estimated Total Size (MB): 2608.22\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oModel = GetModel()\n",
    "\n",
    "oModel = oModel.to(TORCH_DEVICE) #<! Transfer model to device\n",
    "# torchinfo.summary(oModel, train_images.shape, device = TORCH_DEVICE)\n",
    "\n",
    "train_images = (train_images[0], train_images[1], train_images[2])\n",
    "# Pass the tuple of tensors as input to `torchinfo.summary`\n",
    "torchinfo.summary(oModel, input_data=train_images, device=TORCH_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logger \n",
    "# Wrapper of TensorBoard's `SummaryWriter` with index for iteration and epoch.\n",
    "\n",
    "class TBLogger():\n",
    "    def __init__( self, logDir: Optional[str] = None ) -> None:\n",
    "\n",
    "        self.oTBWriter  = SummaryWriter(log_dir = logDir)\n",
    "        self.iiEpcoh    = 0\n",
    "        self.iiItr      = 0\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def close( self ) -> None:\n",
    "\n",
    "        self.oTBWriter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Score function \n",
    "\n",
    "def Score(mScore: np.ndarray, vY: np.ndarray ) -> np.float64:\n",
    "    \n",
    "    preds = mScore >= 0.5\n",
    "    valAcc = (preds.eq(vY).sum())/len(vY)\n",
    "\n",
    "    return valAcc\n",
    "\n",
    "#Loss function \n",
    "\n",
    "# Fix unbalance images\n",
    "\n",
    "# # Compute manually\n",
    "# train_labels = train_labels.long().flatten()          # Convert to integers (int64) and convert to 1 dim\n",
    "# class_counts = torch.bincount(train_labels)\n",
    "# total_samples = len(train_labels)\n",
    "# class_weights = total_samples / (2.0 * class_counts)  # Calculate class weights (inversely proportional to class frequency)\n",
    "# pos_weight = torch.tensor([class_weights[1]]).to(TORCH_DEVICE)\n",
    "# hL = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "# # Compute with function: compute_class_weight\n",
    "# train_labels_cpu = train_labels.cpu().numpy() #need to pass to numpy from torch for compute class function \n",
    "# class_weights = compute_class_weight('balanced', classes=np.unique(train_labels_cpu), y=train_labels_cpu.flatten())\n",
    "# class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "hL=nn.BCEWithLogitsLoss()#(pos_weight=class_weights[1])\n",
    "\n",
    "# # Calculate the number of positive and negative samples -POS WEIGHT -got lower score 65\n",
    "# num_pos = (train_labels_cpu == 1).sum()\n",
    "# num_neg = (train_labels_cpu == 0).sum()\n",
    "# pos_weight = num_neg / num_pos\n",
    "# pos_weight = torch.tensor([pos_weight], dtype=torch.float).to(TORCH_DEVICE)\n",
    "# hL = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "hL=hL.to(TORCH_DEVICE)\n",
    "\n",
    "\n",
    "TENSOR_BOARD_BASE   = 'TB'\n",
    "\n",
    "nEpochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # kaiming Weight initialization function\n",
    "# def initialize_weights_he(model):\n",
    "#     for layer in model.modules():\n",
    "#         if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "#             nn.init.kaiming_uniform_(layer.weight, nonlinearity='leaky_relu')\n",
    "#             if layer.bias is not None:\n",
    "#                 nn.init.zeros_(layer.bias)\n",
    "\n",
    "\n",
    "# # Apply weight initialization\n",
    "# initialize_weights_he(oModel)\n",
    "\n",
    "\n",
    "# # Xavier initialization function\n",
    "# def initialize_weights_xavier(model):\n",
    "#     for layer in model.modules():\n",
    "#         if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "#             nn.init.xavier_uniform_(layer.weight)  # Use xavier_normal_ if you prefer normal distribution\n",
    "#             if layer.bias is not None:\n",
    "#                 nn.init.zeros_(layer.bias)\n",
    "\n",
    "# # Apply weight initialization\n",
    "# initialize_weights_xavier(oModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 1/20 - Batch 6948/7050 - Loss: 0.7032 - Gradient Norm: 0.2324"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m oTBLogger \u001b[38;5;241m=\u001b[39m TBLogger(logDir\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(TENSOR_BOARD_BASE, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel_SiameseNetwork\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m oRunModel, history \u001b[38;5;241m=\u001b[39m \u001b[43mTrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moOpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moScd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnEpochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTORCH_DEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_binary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moTBLogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/clone/Diana/Final projects/DLfunctions.py:107\u001b[0m, in \u001b[0;36mTrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device, is_binary, save_metric, oTBLogger)\u001b[0m\n\u001b[1;32m    102\u001b[0m all_train_probs \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;66;03m#To Plot the distribution of predicted probabilities\u001b[39;00m\n\u001b[1;32m    105\u001b[0m total_train_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[0;32m--> 107\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_norm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Reset for each batch\u001b[39;49;00m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# If multiple images (e.g Siamese network), move each to the device\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/EnvCUDA/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/EnvCUDA/lib/python3.11/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/EnvCUDA/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/EnvCUDA/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[13], line 79\u001b[0m, in \u001b[0;36mCustomTrainDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     76\u001b[0m patient_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mannotations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStudyInstanceUID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[idx]\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Use the load_slices method for image loading and sampling\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatient_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Split into three separate 1-channel images\u001b[39;00m\n\u001b[1;32m     82\u001b[0m image1 \u001b[38;5;241m=\u001b[39m image[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m, :, :]  \u001b[38;5;66;03m# Extract the first channel\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 38\u001b[0m, in \u001b[0;36mCustomTrainDataset.load_image\u001b[0;34m(self, patient_id, idx)\u001b[0m\n\u001b[1;32m     35\u001b[0m path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_dir, patient_id, group_series, patient_files[i_idx])\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#reading image\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mski\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# image = imread(path)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Check if the image has only one channel, convert it to 3 channels\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(image\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/EnvCUDA/lib/python3.11/site-packages/skimage/io/_io.py:60\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[1;32m     57\u001b[0m         plugin \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtifffile\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_or_url_context(fname) \u001b[38;5;28;01mas\u001b[39;00m fname:\n\u001b[0;32m---> 60\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcall_plugin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimread\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplugin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplugin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mplugin_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(img, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/miniconda3/envs/EnvCUDA/lib/python3.11/site-packages/skimage/io/manage_plugins.py:217\u001b[0m, in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not find the plugin \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplugin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkind\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/EnvCUDA/lib/python3.11/site-packages/skimage/io/_plugins/imageio_plugin.py:11\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(imageio_imread)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimread\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 11\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[43mimageio_imread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWRITEABLE\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     13\u001b[0m         out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/miniconda3/envs/EnvCUDA/lib/python3.11/site-packages/imageio/v3.py:53\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(uri, index, plugin, extension, format_hint, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     call_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m index\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mimopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mplugin_kwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m img_file:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(img_file\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcall_kwargs))\n",
      "File \u001b[0;32m~/miniconda3/envs/EnvCUDA/lib/python3.11/site-packages/imageio/core/imopen.py:196\u001b[0m, in \u001b[0;36mimopen\u001b[0;34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m     plugin_instance \u001b[38;5;241m=\u001b[39m \u001b[43mcandidate_plugin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InitializationError:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;66;03m# file extension doesn't match file type\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/EnvCUDA/lib/python3.11/site-packages/imageio/plugins/pillow.py:85\u001b[0m, in \u001b[0;36mPillowPlugin.__init__\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Register HEIF opener for Pillow\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpillow_heif\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_heif_opener\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1138\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1078\u001b[0m, in \u001b[0;36m_find_spec\u001b[0;34m(name, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1507\u001b[0m, in \u001b[0;36mfind_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1479\u001b[0m, in \u001b[0;36m_get_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1615\u001b[0m, in \u001b[0;36mfind_spec\u001b[0;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[0;34m(path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "oModel = oModel.to(TORCH_DEVICE)\n",
    "\n",
    "# Initial optimizer and scheduler\n",
    "learnRate = 4e-3\n",
    "oOpt = torch.optim.AdamW(oModel.parameters(), lr=6e-4, betas=(0.9, 0.99), weight_decay=1e-3)\n",
    "oScd = torch.optim.lr_scheduler.OneCycleLR(oOpt, max_lr=learnRate, total_steps=nEpochs * len(train_loader))\n",
    "\n",
    "# TensorBoard logger setup\n",
    "oTBLogger = TBLogger(logDir=os.path.join(TENSOR_BOARD_BASE, 'Model_SiameseNetwork'))\n",
    "\n",
    "\n",
    "# Train the model\n",
    "oRunModel, history = Train_model(model=oModel, train_loader=train_loader, val_loader=test_loader, criterion=hL, optimizer=oOpt, scheduler=oScd, num_epochs=nEpochs, device=TORCH_DEVICE, is_binary=True, save_metric='f1', oTBLogger=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Load the best model checkpoint\n",
    "# checkpoint = torch.load('BestModel.pt', weights_only=False)  # Make sure 'weights_only=False' since you're loading other states like optimizer, etc.\n",
    "# model = GetModel(num_classes=1)  # Initialize the model\n",
    "# model.load_state_dict(checkpoint['Model'])  # Load the model's state dictionary\n",
    "\n",
    "# # Switch the model to evaluation mode\n",
    "# model.eval()\n",
    "\n",
    "# # Example input tensor for extracting features (batch_size=1, channels=3, height=224, width=224)\n",
    "# input_tensor = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# # Extract features using the `extract_features` method\n",
    "# with torch.no_grad():  # Disable gradients for faster inference\n",
    "#     features = model.extract_features(input_tensor)\n",
    "\n",
    "# # Print the shape of the extracted features\n",
    "# print(f\"Extracted Features Shape: {features.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize_feature_maps(feature_maps, num_feature_maps_to_show=5):\n",
    "#     # Loop over feature maps from each layer\n",
    "#     for i, fmap in enumerate(feature_maps):\n",
    "#         fmap = fmap.detach().cpu().numpy()  # Convert to numpy array and detach from computation graph\n",
    "        \n",
    "#         # Take a few channels to display\n",
    "#         num_channels = fmap.shape[1]\n",
    "#         print(f\"Layer {i} has {num_channels} channels.\")\n",
    "        \n",
    "#         # Display a few channels\n",
    "#         for j in range(min(num_feature_maps_to_show, num_channels)):\n",
    "#             plt.imshow(fmap[0, j], cmap='viridis')\n",
    "#             plt.title(f\"Feature map from layer {i}, channel {j}\")\n",
    "#             plt.axis('off')\n",
    "#             plt.show()\n",
    "\n",
    "# # Initialize and load the model\n",
    "# model = GetModel(num_classes=1)\n",
    "# model.eval()\n",
    "\n",
    "# # Example input tensor\n",
    "# input_tensor = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# # Extract feature maps\n",
    "# with torch.no_grad():\n",
    "#     feature_maps = model(input_tensor, return_feature_maps=True)\n",
    "\n",
    "# # Visualize feature maps\n",
    "# visualize_feature_maps(feature_maps, num_feature_maps_to_show=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EnvCUDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
